# Byte Ordering
	데이터가 저장되는 순서를 의미
	빅엔디안과 리틀엔디안이 있다.
* 빅엔디안
```
MSB(Most Significant Byte)가 가장 낮은 주소에 위치하는 저장 방식
네트워크에서 데이터를 전송할 때 주로 사용됨
가장 낮은 주소에 MSB가 저장되므로 offset=0인 Byte를 보면 양수/음수 판별 가능
소프트웨어의 디버그를 편하게 해주는 경향이 있다.
사람이 숫자를 읽고 쓰는 방식과 같기에
```
* 리틀엔디안
```
MSB가 가장 높은 주소에 위치하는 방식
마이크로 프로세서에서 주로 사용
가장 낮은 주소에 부호값이 아닌 데이터가 먼저오기 때문에 바로 연산 가능
메모리에 저장된 값의 하위 바이트만 사용할 때 별도의 계산이 필요 없다
```

# 메모리란
	메모리는 컴퓨터에서 작업을 수행하기 위해 처리 대상이나 결과등을 저장하기 위한 공간
	프로그램 실행하기 위한 정보들은 메모리에 저장되어 처리

# RAM vs ROM
* RAM
```
휘발성 메모리
프로그램 데이터 일시적으로 저장할 때 이용
sRAM, DRAM, SDRAM, DDR SDRAM
```
* ROM
```
비휘발성 메모리
* mask ROM
회사에서 제조시 데이터를 기록함
* PROM
유저가 데이터를 기록할 수 있는 ROM
OTP, EPROM, EEPROM, UVEPROM
```
# 프로세스와 쓰레드의 차이
* 프로세스 - 메모리에 올라와 실행되고 있는 프로그램의 인스턴스
```
운영체제로부터 독립된 메모리 영역 할당(다른 프로세스의 자원에 접근 X)
프로세스들은 독립적이기 때문에 통신 위해 IPC 사용
프로세스는 최소 1개의 쓰레드를 가지고 있다.
```

* 쓰레드 - 프로세스 내에서 할당받은 자원을 이용해 동작하는 실행 단위
```
쓰레드는 프로세스 내에서 Stack만 따로 할당 받고 Code, Data, Heap영역은 공유
Stack에는 함수의 호출 정보 저장되는데 Stack을 공유하면 LIFO 구조에 의해 실행 순서 복잡해지기에 따로 분리
쓰레드는 프로세스의 자원을 공유하기 때문에 다른 쓰레드에 의한 결과 즉시 확인 가능
프로세스 내에 존재하며 프로세스가 할당받은 자원을 이용하여 실행
```

# Context Switching
	컨텍스트 스위칭이란 인터럽트를 발생시켜 CPU에서 실행중인 프로세스를 중단하고 다른 프로세스를 처리하기 위한 과정
	현재 실행중인 프로세스의 상태(Context)를 저장하고 다음 프로세스를 동작시켜 작업 처리한 후에 이전에 저장된 프로세스의 상태를 다시 복구
	인터럽트란 CPU가 프로세스를 실행하고 있을 때, 입출력 하드웨어등의 장치나 예외 상황이 발생하여 처리가 필요함을 CPU에게 알리는 것

# race condition(경쟁 상태)
	둘 이상의 입력 또는 조작의 타이핑이나 순서 등이 결과값에 영향을 줄 수 있는 상태

# 멀티 프로세스 VS 멀티 쓰레드
* 멀티 프로세스 - 하나의 프로그램을 여러 개의 프로세스로 구성하여 각 프로세스가 1개의 작업을 처리하도록 하는 것
```
1개의 프로세스가 죽어도 자식 프로세스 이외의 다른 프로세스들은 계속 실행
context switching을 위한 오버헤드가 발생
프로세스는 각각 독립적인 메모리를 할당 받았기에 통신이 어렵다
```
* 멀티 쓰레드 - 하나의 프로그램을 여러개의 쓰레드로 구성하여 각 쓰레드가 1개의 작업을 처리하는 것
```
프로세스를 위해 자원을 할당하는 시스템콜이나 context switching의 오버헤드 줄어듦
쓰레드는 메모리 공유하기에 통신이 쉽고, 자원을 효율적으로 이용 가능
하나의 쓰레드에 문제가 생기면 전체 프로세스가 영향을 받는다.
여러 쓰레드가 하나의 자원에 동시에 접근하는 경우 자원 공유(동기화)의 문제가 발생 가능
```

# 데드락(교착상태) - 한정된 자원을 여러 프로세스가 사용하고자 할때 발생하는 상황
	P1이 B 가지고 있고 C 기다림
	P2는 C 가지고 있고 B 기다림
	둘이 무한정 기다리게 됨
* 4가지 조건
```
상호배제 (Mutual Exclusion) - 한번에 한개의 프로세스만이 공유 자원 사용할 수 있어야 한다.
점유와 대기(Hold and Wait) - 최소한 하나의 자원 점유하고 있으면서 다른 프로세스에 할당되어 사용되고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스 있어야 함
비선점(Non-preemption) - 다른 프로세스에 할당된 자원은 사용이 끝나기 전에 강제로 빼앗을수 없다.
환형 대기(Circular Wait) - 공유자원가 공유자원을 사용하기 위해 대기하는 프로세스들이 원형으로 구성되어 있어 할당된 자원 점유하면서 앞이나 뒤에 있는 프로세스의 자원 요구해야 한다.
```
* 예방 기법
```
상호 배제(Mutual Exclusion)부정 : 한번에 여러개의 프로세스가 공유 자원을 사용할 수 있도록 합니다.
점유 및 대기(Hold and Wait) 부정 : 프로세스가 실행되기 전 필요한 모든 자원을 할당하여 프로세스 대기를 없애거나 자원이 점유되지 않은 상태에서만 자원을 요구하도록 합니다.
비선점(Non-preemption)부정 : 자원을 점유하고 있는 프로세스가 다른 자원을 요구할 때 점유하고 있는 자원을 반납하고, 요구한 자원을 사용하기 위해 기다리게 합니다.
환형 대기(Circular Wait)부정 : 자원을 선형 순서로 분류하여 고유 번호를 할당하고, 각 프로세스는 현재 점유한 자원의 고유 번호보다 앞이나 뒤 어느 한쪽 방향으로만 자원을 요구하도록 하는것입니다.
```
* 회피 기법
```
은행원 알고리즘
	1. 은행원 알고리즘은 다익스트라가 제안한 기법으로, 은행에서 모든 고객의 요구가 충족되도록 현금을 할당하는데서 유래한 기법입니다.
	2. 각 프로세스에게 자원을 할당하여 교착상태가 발생하지 않으며 모든 프로세스가 완료될 수 있는 상태를 안전상태, 교착상태가 발생할 수 있는 상태를 불안전 상태라고 합니다.
	3. 은행원 알고리즘을 적용하기 위해서는 자원의 양과 사용자(프로세스) 수가 일정해야 합니다.
	4. 은행원 알고리즘은 프로세스의 모든 요구를 유한한 시간안에 할당하는 것을 보장합니다.
```
* 발견 기법
* 회복 기법

# 사용자 수준 쓰레드 vs 커널 수준 쓰레드
	사용자 수준 쓰레드는 쓰레드 라이브러리를 이용하여 작동하는 형태이고 다대일 매핑이다
	커널 수준 쓰레드는 일대일 매핑이고 커널에서 지원하는 형태이다.
	이 둘을 혼합한 형태인 다대다 매핑의 혼합형 쓰레드가 있다.

# CPU 스케줄링
	CPU 스케줄링은 프로세스가 작업을 수행할 때 언제 어떤 프로세스에 CPU를 할당할지를 결정하는 작업입니다.
	스케줄링은 OS가 강제적으로 CPU사용을 중단시키는지 여부에 따라서 강제할 경우 선점형(preemptive) 강제하지 않는 경우 비선점형(non-preemptive) 스케쥴링으로 나뉜다.
* 선점형 스케줄링 - time quantum을 가지고 time quantum이 지나면 프로세스가 남아있어도 강제적으로 바꾸는 방식
** Round Robin Scheduling
	```
	CPU를 시간단위(time quantum)로 할당하는 선점형 스케줄링 방식
	먼저 대기한 작업이 먼저 CPU를 사용
	time quantum만큼 사용한 후 대기큐의 가장 끝으로 배치되어 재할당 기다림
	response time이 짧다.
	시간 단위가 클경우 FCFS와 비슷해지고
	시간단위가 너무 작을경우 잦은 context switching으로 인한 오버헤드로 인해 효율이 매우 떨어질 수 있다.
	```
** Multilevel Queue Scheduling
	```
	ready 큐를 여러개 만들어 각각에 다른 우선순위와 스케줄링 알고리즘 사용하는 기법
	Interactive한 동작이 필요한 프로세스 위한 Foreground 큐와 
	RR 스케줄링 사용
	CPU 연산 작업 주로 수행하는 Background 큐
	FCFC 스케줄링 사용
	상위 큐에 프로세스가 계속 있으면 하위 큐에 기아 현상 발생 가능
	```
** Multilevel Feedback Queue Scheduling
	```
	다단계 큐에서 프로세스들이 다른 큐로 이동할 수 있게 한 스케줄링 기법
	design choices
	큐의 개수
	각 큐마다의 스케줄링 기법
	언제 프로세스를 높은 큐로 옮길것인지
	언제 프로세스를 낮은 큐로 옮길것인지
	```
* 비선점형 스케줄링 - 프로세스가 I/O를 하는 상황에서만 수행되는 스케줄링
** FCFS(First Come First Served) scheduling
```
선착순 방식의 스케줄링으로 비선점형 스케줄링이다.
먼저 들어온 순서대로 CPU를 할당한다.
작업의 순서에 따라서 대기시간이 변한다.
```
** SJFS(Shortest Job First Scheduling) scheduling
```
가장 CPU Burst 시간이 짧은 프로세스부터 CPU에 할당하는 방식
비선점형 선점형 둘다 가능하다.
최소의 평균 대기시간을 제공한다는 특징이 있다.
```
** Priority Scheduling
```
프로세스에 우선순위를 주고 우선순위에 따라 CPU에 순서대로 할당하는 스케줄링 방식
비선점형, 선점형 둘다가능
낮은 우선순위의 프로세스는 늦게 수행되거나 수행되지 못할 수도있는 기아(starvation) 문제 발생 가능
```
*** 기아 문제를 해결하기 위해 Aging 기법 사용
	```
	기다리는 시간 늘어날수록 우선순위 증가시켜주는 방법
	우선순위를 정적, 동적으로 주는 방법 둘다 가능
	동적일 경우 시스템 응답속도 증가시키는 장점이 있지만 오버헤드가 늘어날 수 있는 단점도 있다.
	```
# 멀티플 코어 스케줄링
	멀티 코어는 확장성이 좋다.
	GPU의 경우 많은수의 코어를 병렬적으로 처리하는데 멀티코어 방식이 성능적으로 유리
* 스케줄링 방식
```
Load Balancing	
Cache Affinity
```
* 스케줄링 기준
```
CPU 활용률
처리량
응답 시간
대기 시간
Turnaround Time -  프로세스가 시작해서 끝날때까지 걸리는 시간
```
# 프로세스 스레드의 동기화
	여러 프로세스나 스레드가 공유하는 자원의 일관성을 유지하는 것입니다.
	하나의 코드 블록 또는 메소드를 한순간에 하나의 프로세스나 스레드만 이용하도록 보장하는 것

# 멀티쓰레드 프로그래밍 작성 시 유의점
	다수의 쓰레드가 공유 데이터에 동시에 접근하는 경우에 상호배제 또는 동기화 기법을 통해 동시성 문제 또는 교착상태 발생하지 않도록 주의해야함

# 세마포어 vs 뮤텍스
* 뮤텍스
```
뮤텍스는 Locking 메커니즘으로 락을 걸은 쓰레드만이 critical section을 나갈때 락을 해제 가능
```
* 세마포어
```
세마포어는 signaling 메커니즘으로 락을 걸지 않은 쓰레드도 signal 이용해 락 해제 가능
세마포어의 카운트를 1로 설정하면 뮤텍스처럼 활용 가능
```

# CPU의 메모리 I/O 도중 생기는 병목 현상 해결 방법
	메모리를 계층화 하여 병목현상 해결
	자주 접근하는 데이터의 경우 캐시에 저장하여 접근속도 향상시켜 부하 줄인다.

# 가상메모리와 페이지 폴트
	가상메모리는 RAM의 부족한 용량 보완하기 위해 각 프로그램에 실제 메모리 주소가 아닌 가상의 메모리 주소 할당하는 방식
	OS는 프로세스들의 내용(페이지)중에서 덜 중요한 것들을 하드디스크에 옮겨 놓고 관련 정보를 페이지 테이블에 기록
	CPU는 프로세스 실행 중 페이지 테이블을 통해 페이지 조회를 하는데 실제 메모리에 원하는 페이지가 없는 상황 발생 가능
* 페이지 폴트
```
프로세스가 동작하면서 실제 메모리에 필요한 데이터(페이지)가 없으면 가상 메모리를 통해서 해당 데이터 가져오게 됨
가상 메모리는 하드디스크에 저장되어 있기 때문에, 페이지 폴트 발생시 I/O에 의한 속도저하 발생
```

# 페이지 교체 알고리즘 & LRU(Least Recently Used)
* 페이지 교체하는 이유
```
가상메모리를 통해 조회한 페이지는 다시 사용될 가능성이 높기 때문
페이지 교체를 위해서는 실제 메모리에 존재하는 페이지를 가상메모리로 저장한 후에, 가상 메모리에서 조회한 페이지를 실제 메모리로 로드
이러한 과정에서 실제메모리의 페이지를 가상메모리로 희생시킬 것이냐에 대한 문제 발생
```
* LRU
```
실제 메모리의 페이지들 중에서 가장 오랫동안 사용되지 않은 페이지 선택하는 방식
FIFO 알고리즘
```
* LRU Approximation
```
Additional reference bits algorithm
일정 시간 간격으로 reference bit을 기록하여 추가 ordering information얻을 수 잇따.
페이지에 Second-Chance를 주는 알고리즘
페이지에 오래머무른 것을 victim으로 결정
but 계속 접근이 되고 있는 page면 메모리에 남아있을 기회 줌
하드웨어 지원 없이 Reference-Bit(해당 page가 invalid인지 valid인지)을 이용하여 구현된 알고리즘
```
# 페이지와 세그멘테이션
* 페이지
```
가상메모리는 페이지라는 고정 크기의 블록으로 나뉘어진다.
페이지는 고정적인 데이터이며 시스템에 의해서 할당받는 메모리
페이징은 페이지로 가상 메모리를 분할하여 메모리를 할당하고 주소변환을 하는 기법
```
* 세그먼트, 세그멘테이션
```
같은 크기가 아닌 서로 다른 크기의 블록으로 나누는 개념
가변적인 데이터이며 사용자의 필요에 의한 메모리(malloc, calloc)
세그멘테이션은 가상 메모리를 세그먼트로 분할하여 메모리를 할당하고 주소변환을 하는 기법
세그먼트는 논리적 단위여서 중요도에 따라 나눌수 잇고 용도에 따라 나눌수도 있다.
페이지와는 다르게 미리 메모리를 분할해 둘 수 없고(크기 가변) 사용자 관점의 가상 메모리 관리 기법
외부 단편화 발생 가능(분할된 크기보다 프로그램의 크기가 더 큰 경우)
```
# 내부 단편화와 외부 단편화
* 내부 단편화
```
빈 공간이 50MB인데 프로세스가 30MB일 경우 20MB의 공간이 남음
저 공간은 작아 다른 작업이 이용하지 못하게 되는데 이러한 작은 빈공간(낭비)를 내부 단편화라 한다.
```
* 외부 단편화
```
메모리에 남은 공간은 100MB(50MB + 50MB)인데 들어오는 작업이 70MB일때 발생
100MB 의용량이 있지만 새 작업은 메모리에 들어가지 못하게 된다.
작업보다 많은 공간이 남아 있더라도 작업을 받아들이지 못하는 경우 를 외부단편화라 한다.
```
* 해결 방법
** 압축
```
빈 공간들을 한쪽으로 몰아서 큰 공간으로 만드는 기법
```

# first fit
	프로세스가 들어올때 가장 최초로 발견되는 공간에 할당하는 것
	남은 메모리를 순차적으로 탐색하다가 최초발견 공간에 배치

# best fit
	모든 공간에 다 넣는것을 비교해보고 가장 내부단편화(빈공간이 적은)가 적은 공간에 할당하는 것

# worst fit
	가장 큰 공간에다가 할당하는 것
	적합한 곳 있어도 그냥 가장 큰 곳
	내부단편화가 크면 다른 프로세스가 또 들어갈 확률이 크다
